{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "import config_twit\n",
    "import jsonpickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "query = '#kathua OR \"kathua\" AND \"rape\"'\n",
    "max_tweets = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter your keys/secrets as strings in the following fields. config_twit is a .py file that contains \n",
    "# my twitter api auth codes \n",
    "\n",
    "API_KEY = config_twit.api_key\n",
    "API_SECRET = config_twit.api_secret\n",
    "ACCESS_TOKEN = config_twit.ACCESS_TOKEN\n",
    "ACCESS_TOKEN_SECRET = config_twit.ACCESS_TOKEN_SECRET\n",
    "\n",
    "# assuming twitter_authentication.py contains each of the 4 oauth elements (1 per line)\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from tweets that match search terms \n",
    "\n",
    "searched_tweets = [status for status in tweepy.Cursor(api.search, q=query).items(max_tweets)]\n",
    "tweet_id = [s.id for s in searched_tweets]\n",
    "user_id = [s.user.id for s in searched_tweets]\n",
    "screen_name = [s.user.screen_name for s in searched_tweets]\n",
    "followers = [s.user.followers_count for s in searched_tweets]\n",
    "retweet_count = [s.retweet_count for s in searched_tweets]\n",
    "locations = [s.user.location for s in searched_tweets]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%time\n",
    "node:\n",
    "{\"name\":\"Mme.Burgon\",\"group\":7}\n",
    "\n",
    "link:\n",
    "{\"source\":1,\"target\":0,\"value\":1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to parse data into network graph - here make df for convenience but later could have lists\n",
    "\n",
    "screen_name = [s.user.screen_name for s in searched_tweets]\n",
    "df = pd.DataFrame({'tweet_id':tweet_id, 'screen_name':screen_name, 'source':user_id, 'followers':followers, 'locations':locations})\n",
    "most_followed_tweeters = df.sort_values(by='followers', ascending=False).head(10).drop_duplicates(subset='screen_name')\n",
    "most_followed_tweets = zip(most_followed_tweeters.tweet_id, most_followed_tweeters.source, \n",
    "                           most_followed_tweeters.followers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Links list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make links list: get retweet list of each tweet\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "\n",
    "users_retweeted_dict ={}\n",
    "\n",
    "retweet_lst_names=[]\n",
    "for status_id, user_id, followers in most_followed_tweets:\n",
    "    \n",
    "    retweet_lst=[]\n",
    "    retweet_lst_name =[]\n",
    "    \n",
    "    for retweet_id in api.retweets(status_id):\n",
    "        retweet_lst.append(retweet_id.user.id)\n",
    "        retweet_lst_name.append(retweet_id.user.name)\n",
    "\n",
    "    users_retweeted_dict[user_id] = retweet_lst\n",
    "    retweet_lst_names.append(retweet_lst_name)\n",
    "\n",
    "# flatten list\n",
    "retweet_lst_names = [j for i in retweet_lst_names for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then replace tweet id with index number\n",
    "\n",
    "links_lst=[]\n",
    "for k in users_retweeted_dict:\n",
    "\n",
    "    if users_retweeted_dict[k]:\n",
    "        for u in users_retweeted_dict[k]:\n",
    "            links_lst.append({\"source\":k,\"target\":u})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get followers counts\n",
    "\n",
    "top_tweeters_follower_counts=[]\n",
    "mft = most_followed_tweeters.followers\n",
    "\n",
    "normalized_followers = np.round((np.abs(np.array(mft)-np.array(mft).mean())/mft.std())*10, 0)\n",
    "\n",
    "\n",
    "\n",
    "count=0\n",
    "\n",
    "for i in links_lst:\n",
    "    for j,k in zip(most_followed_tweeters.source, normalized_followers ) :\n",
    "        \n",
    "        if i['source'] == j:\n",
    "            \n",
    "            top_tweeters_follower_counts.append(int(k))\n",
    "    \n",
    "    \n",
    "# for k,v in zip(most_followed_tweeters.user_id, most_followed_tweeters.followers):\n",
    "    \n",
    "    \n",
    "#    most_followed_tweeters.followers\n",
    "# links_lst[0]['source']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all elements in link list together\n",
    "\n",
    "count=0\n",
    "count1=0\n",
    "links_r =[]\n",
    "for k,v in users_retweeted_dict.items():\n",
    "    count1+=1\n",
    "    for y,t in zip(most_followed_tweeters.source, normalized_followers ):\n",
    "        if y == k:\n",
    "            value = t\n",
    "    for i in v:\n",
    "        count+=1\n",
    "        links_r.append({\"source\":count1, \"target\": count, \"value\": int(value)})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Node list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# node: make \"group\" from location\n",
    "\n",
    "location_india =[]\n",
    "for i in most_followed_tweeters.locations:\n",
    "    if 'India' or 'New Delhi' in i:\n",
    "        location_india.append(1)\n",
    "    else:\n",
    "        location_india.append(0)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make nodes lst\n",
    "\n",
    "nodes_lst = []\n",
    "for x,y in zip(most_followed_tweeters.screen_name, location_india):\n",
    "     nodes_lst.append({\"name\":x, \"group\":y})\n",
    "\n",
    "for x,y in enumerate(retweet_lst_names):\n",
    "     nodes_lst.append({\"name\":y, \"group\":2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# putting it together\n",
    "data = {}\n",
    "data['nodes'] = nodes_lst\n",
    "data['links'] = links_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data_twitter.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# build the dataframe\n",
    "# friends = [s.user.friends_count for s in searched_tweets]\n",
    "# user_created_at = [s.user.created_at for s in searched_tweets]\n",
    "# tweet_source = [s.source for s in searched_tweets] \n",
    "# friends = [s.user.favourites_count for s in searched_tweets]\n",
    "# listed_count = [s.user.listed_count for s in searched_tweets]\n",
    "# language = [s.lang for s in searched_tweets]\n",
    "# posted_date = [s.created_at for s in searched_tweets]\n",
    "# messages = [s.text.encode('utf8') for s in searched_tweets]\n",
    "# user_name = [s.user.name for s in searched_tweets]\n",
    "\n",
    "'''\n",
    "df = pd.DataFrame(\n",
    "    {'tweet_id':tweet_id,'user_id':user_id,'posted_date':posted_date, 'tweet_source':tweet_source, 'messages': messages, \n",
    "     'user_name':user_name, 'screen_name':screen_name, 'locations':locations, 'followers':followers,\n",
    "     'retweet_count':retweet_count, 'friends':friends, 'user_created_at': user_created_at, \n",
    "     'friends':friends, 'listed_count':listed_count, 'language':language})\n",
    "'''\n",
    "\n",
    "# output to json file for downloading\n",
    "# df.to_json('twitter_search_word_{}.json'.format(timestr))\n",
    "# print(df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
